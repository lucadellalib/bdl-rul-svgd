# Bayesian Deep Learning for Remaining Useful Life Estimation via Stein Variational Gradient Descent

This is the official code accompanying the paper [Bayesian Deep Learning for Remaining Useful Life Estimation via Stein Variational Gradient Descent](https://arxiv.org/abs/2402.01098).

In this work, we explore the use of [Stein variational gradient descent (SVGD)](https://arxiv.org/abs/1608.04471)
for training Bayesian deep learning models for remaining useful life (RUL) estimation. In particular, we investigate whether
Bayesian deep learning models trained via SVGD can outperform in terms of convergence speed and predictive performance both
the same models trained via [Bayes by Backprop (BBB)](https://arxiv.org/abs/1505.05424), which is the de-facto standard for
training large scale Bayesian neural networks, and their frequentist counterparts trained via backpropagation (BP). For the
experimental evaluation, we use the popular [Commercial Modular Aero-Propulsion System Simulation (C-MAPSS)](https://ieeexplore.ieee.org/abstract/document/4711414) dataset.

---------------------------------------------------------------------------------------------------------

## üõ†Ô∏èÔ∏è Installation

First of all, install [Miniconda](https://docs.conda.io/en/latest/miniconda.html).
Clone or download and extract the repository, navigate to `<path-to-repository>`, open a terminal and run:

```
conda env create -f environment.yml
```

Project dependencies (pinned to a specific version to reduce compatibility and reproducibility issues)
will be installed in a [Conda](https://www.anaconda.com/) virtual environment named `bdl-rul-svgd`.

To activate it, run:

```
conda activate bdl-rul-svgd
```

To deactivate it, run:

```
conda deactivate
```

To permanently delete it, run:

```
conda remove -n bdl-rul-svgd --all -y
```

---------------------------------------------------------------------------------------------------------

## ‚ñ∂Ô∏è Quickstart

### Running an experiment

To train one of the available deep learning model (`d3` or `c2p2`) on a subset of the C-MAPSS dataset
(`fd001`, `fd002`, `fd003` or `fd004`) using one of the available training algorithms (`bp`, `bbb` or `svgd`),
open a terminal and run:

```
conda activate bdl-rul-svgd
python train_<algorithm>.py <model> <subset>
```

Results (logs, metrics, checkpoints, etc.) can be found in the auto-generated `experiments` directory.

### Reproducing the experimental results

The experiments were run on an Ubuntu 20.04.5 LTS machine with an Intel i7-10875H CPU
with 8 cores @ 2.30 GHz, 32 GB RAM and an NVIDIA GeForce RTX 3070 GPU @ 8 GB with CUDA Toolkit 11.3.1.
To reproduce the experimental results, open a terminal and run:

```
conda activate bdl-rul-svgd
python run_experiments.py
```

---------------------------------------------------------------------------------------------------------

## @ Citing

```bibtex
@article{dellalibera2024bayesian,
  author = {Luca Della Libera and Jacopo Andreoli and Davide Dalle Pezze and Mirco Ravanelli and Gian Antonio Susto},
  title = {Bayesian Deep Learning for Remaining Useful Life Estimation via {S}tein Variational Gradient Descent},
  journal = {arXiv preprint arXiv:2402.01098},
  year = {2024},
  url = {https://arxiv.org/abs/2402.01098},
}
```

---------------------------------------------------------------------------------------------------------

## üìß Contact

[luca.dellalib@gmail.com](mailto:luca.dellalib@gmail.com)

---------------------------------------------------------------------------------------------------------
